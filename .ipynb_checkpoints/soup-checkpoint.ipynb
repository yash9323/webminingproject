{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T22:52:10.892678Z",
     "start_time": "2023-11-09T22:52:09.361419Z"
    }
   },
   "outputs": [],
   "source": [
    "#import dependencies \n",
    "import pandas as pd \n",
    "import requests \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page: 0\n",
      "Processing Page: 1\n",
      "Processing Page: 2\n",
      "Processing Page: 3\n",
      "Processing Page: 4\n",
      "Processing Page: 5\n",
      "Processing Page: 6\n",
      "Processing Page: 7\n",
      "Processing Page: 8\n",
      "Processing Page: 9\n",
      "Processing Page: 10\n",
      "Processing Page: 11\n",
      "Processing Page: 12\n",
      "Processing Page: 13\n",
      "Processing Page: 14\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['title', 'date', 'person', 'link'])\n",
    "base_url = \"https://www.presidency.ucsb.edu/documents/app-categories/elections-and-transitions/campaign-documents?field_docs_start_date_time_value%5Bvalue%5D%5Bdate%5D=2019\"\n",
    "for i in range(0, 15):\n",
    "    print(\"Processing Page:\",i)\n",
    "    if i == 0:\n",
    "        url = base_url\n",
    "    else:\n",
    "        url = base_url + \"&page=\" + str(i)\n",
    "    data = requests.get(url)\n",
    "    h = BeautifulSoup(data.text,\"html.parser\")\n",
    "    dates = [d.find(\"span\",attrs={'class':'date-display-single'})['content'] for d in h.find_all(\"div\",attrs={'class':'views-row'})]\n",
    "    doc_links = [d.find(\"div\",attrs={'class':'field-title'}).find(\"a\") for d in h.find_all(\"div\",attrs={'class':'views-row'})]\n",
    "    titles = [d.string for d in doc_links]\n",
    "    links = [d['href'] for d in doc_links]\n",
    "    persons = [d.find(\"div\",attrs={'class':'col-sm-4'}).find(\"a\").string for d in h.find_all(\"div\",attrs={'class':'views-row'})]\n",
    "    temp = pd.DataFrame({\"title\": titles, \"date\": dates, \"person\": persons, \"link\": links},columns=['title', 'date', 'person', 'link'])\n",
    "    df = pd.concat([df, temp])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_url = 'https://www.presidency.ucsb.edu'\n",
    "df['transcript'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Transcript: 0\n",
      "Fetching Transcript: 1\n",
      "Fetching Transcript: 2\n",
      "Fetching Transcript: 3\n",
      "Fetching Transcript: 4\n",
      "Fetching Transcript: 5\n",
      "Fetching Transcript: 6\n",
      "Fetching Transcript: 7\n",
      "Fetching Transcript: 8\n",
      "Fetching Transcript: 9\n",
      "Fetching Transcript: 10\n",
      "Fetching Transcript: 11\n",
      "Fetching Transcript: 12\n",
      "Fetching Transcript: 13\n",
      "Fetching Transcript: 14\n",
      "Fetching Transcript: 15\n",
      "Fetching Transcript: 16\n",
      "Fetching Transcript: 17\n",
      "Fetching Transcript: 18\n",
      "Fetching Transcript: 19\n",
      "Fetching Transcript: 20\n",
      "Fetching Transcript: 21\n",
      "Fetching Transcript: 22\n",
      "Fetching Transcript: 23\n",
      "Fetching Transcript: 24\n",
      "Fetching Transcript: 25\n",
      "Fetching Transcript: 26\n",
      "Fetching Transcript: 27\n",
      "Fetching Transcript: 28\n",
      "Fetching Transcript: 29\n",
      "Fetching Transcript: 30\n",
      "Fetching Transcript: 31\n",
      "Fetching Transcript: 32\n",
      "Fetching Transcript: 33\n",
      "Fetching Transcript: 34\n",
      "Fetching Transcript: 35\n",
      "Fetching Transcript: 36\n",
      "Fetching Transcript: 37\n",
      "Fetching Transcript: 38\n",
      "Fetching Transcript: 39\n",
      "Fetching Transcript: 40\n",
      "Fetching Transcript: 41\n",
      "Fetching Transcript: 42\n",
      "Fetching Transcript: 43\n",
      "Fetching Transcript: 44\n",
      "Fetching Transcript: 45\n",
      "Fetching Transcript: 46\n",
      "Fetching Transcript: 47\n",
      "Fetching Transcript: 48\n",
      "Fetching Transcript: 49\n",
      "Fetching Transcript: 50\n",
      "Fetching Transcript: 51\n",
      "Fetching Transcript: 52\n",
      "Fetching Transcript: 53\n",
      "Fetching Transcript: 54\n",
      "Fetching Transcript: 55\n",
      "Fetching Transcript: 56\n",
      "Fetching Transcript: 57\n",
      "Fetching Transcript: 58\n",
      "Fetching Transcript: 59\n",
      "Fetching Transcript: 60\n",
      "Fetching Transcript: 61\n",
      "Fetching Transcript: 62\n",
      "Fetching Transcript: 63\n",
      "Fetching Transcript: 64\n",
      "Fetching Transcript: 65\n",
      "Fetching Transcript: 66\n",
      "Fetching Transcript: 67\n",
      "Fetching Transcript: 68\n",
      "Fetching Transcript: 69\n",
      "Fetching Transcript: 70\n",
      "Fetching Transcript: 71\n",
      "Fetching Transcript: 72\n",
      "Fetching Transcript: 73\n",
      "Fetching Transcript: 74\n",
      "Fetching Transcript: 75\n",
      "Fetching Transcript: 76\n",
      "Fetching Transcript: 77\n",
      "Fetching Transcript: 78\n",
      "Fetching Transcript: 79\n",
      "Fetching Transcript: 80\n",
      "Fetching Transcript: 81\n",
      "Fetching Transcript: 82\n",
      "Fetching Transcript: 83\n",
      "Fetching Transcript: 84\n",
      "Fetching Transcript: 85\n",
      "Fetching Transcript: 86\n",
      "Fetching Transcript: 87\n",
      "Fetching Transcript: 88\n",
      "Fetching Transcript: 89\n",
      "Fetching Transcript: 90\n",
      "Fetching Transcript: 91\n",
      "Fetching Transcript: 92\n",
      "Fetching Transcript: 93\n",
      "Fetching Transcript: 94\n",
      "Fetching Transcript: 95\n",
      "Fetching Transcript: 96\n",
      "Fetching Transcript: 97\n",
      "Fetching Transcript: 98\n",
      "Fetching Transcript: 99\n",
      "Fetching Transcript: 100\n",
      "Fetching Transcript: 101\n",
      "Fetching Transcript: 102\n",
      "Fetching Transcript: 103\n",
      "Fetching Transcript: 104\n",
      "Fetching Transcript: 105\n",
      "Fetching Transcript: 106\n",
      "Fetching Transcript: 107\n",
      "Fetching Transcript: 108\n",
      "Fetching Transcript: 109\n",
      "Fetching Transcript: 110\n",
      "Fetching Transcript: 111\n",
      "Fetching Transcript: 112\n",
      "Fetching Transcript: 113\n",
      "Fetching Transcript: 114\n",
      "Fetching Transcript: 115\n",
      "Fetching Transcript: 116\n",
      "Fetching Transcript: 117\n",
      "Fetching Transcript: 118\n",
      "Fetching Transcript: 119\n",
      "Fetching Transcript: 120\n",
      "Fetching Transcript: 121\n",
      "Fetching Transcript: 122\n",
      "Fetching Transcript: 123\n",
      "Fetching Transcript: 124\n",
      "Fetching Transcript: 125\n",
      "Fetching Transcript: 126\n",
      "Fetching Transcript: 127\n",
      "Fetching Transcript: 128\n",
      "Fetching Transcript: 129\n",
      "Fetching Transcript: 130\n",
      "Fetching Transcript: 131\n",
      "Fetching Transcript: 132\n",
      "Fetching Transcript: 133\n",
      "Fetching Transcript: 134\n",
      "Fetching Transcript: 135\n",
      "Fetching Transcript: 136\n",
      "Fetching Transcript: 137\n",
      "Fetching Transcript: 138\n",
      "Fetching Transcript: 139\n",
      "Fetching Transcript: 140\n",
      "Fetching Transcript: 141\n",
      "Fetching Transcript: 142\n",
      "Fetching Transcript: 143\n",
      "Fetching Transcript: 144\n",
      "Fetching Transcript: 145\n",
      "Fetching Transcript: 146\n",
      "Fetching Transcript: 147\n",
      "Fetching Transcript: 148\n",
      "Fetching Transcript: 149\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    print(\"Fetching Transcript:\",i)\n",
    "    url = home_url + df.loc[i, 'link']\n",
    "    data = requests.get(url)\n",
    "    h = BeautifulSoup(data.text, \"html.parser\")\n",
    "    transcript = h.find('div', attrs={'class':'field-docs-content'}).text\n",
    "    df.loc[i, 'transcript'] = transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>person</th>\n",
       "      <th>link</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remarks at Old South Meeting House in Boston, ...</td>\n",
       "      <td>2019-12-31T00:00:00+00:00</td>\n",
       "      <td>Elizabeth Warren</td>\n",
       "      <td>/documents/remarks-old-south-meeting-house-bos...</td>\n",
       "      <td>\\n[As prepared for delivery.]\\nIn a few hours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steyer Campaign Press Release - Tom Steyer Rea...</td>\n",
       "      <td>2019-12-31T00:00:00+00:00</td>\n",
       "      <td>Tom Steyer</td>\n",
       "      <td>/documents/steyer-campaign-press-release-tom-s...</td>\n",
       "      <td>\\n(SAN FRANCISCO, December 31, 2019) — Today, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biden Campaign Press Release - Biden for Presi...</td>\n",
       "      <td>2019-12-31T00:00:00+00:00</td>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>/documents/biden-campaign-press-release-biden-...</td>\n",
       "      <td>\\nCampaign Continues Growing Super Tuesday Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Article by Mike Bloomberg - You're In Charge: ...</td>\n",
       "      <td>2019-12-31T00:00:00+00:00</td>\n",
       "      <td>Michael Bloomberg</td>\n",
       "      <td>/documents/article-mike-bloomberg-youre-charge...</td>\n",
       "      <td>\\nThis article was written by Mike Bloomberg.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump Campaign Statement - Happy New Year from...</td>\n",
       "      <td>2019-12-31T00:00:00+00:00</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>/documents/trump-campaign-statement-happy-new-...</td>\n",
       "      <td>\\nAs we ring in a New Year, Brad Parscale, Cam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   \n",
       "0  Remarks at Old South Meeting House in Boston, ...  \\\n",
       "1  Steyer Campaign Press Release - Tom Steyer Rea...   \n",
       "2  Biden Campaign Press Release - Biden for Presi...   \n",
       "3  Article by Mike Bloomberg - You're In Charge: ...   \n",
       "4  Trump Campaign Statement - Happy New Year from...   \n",
       "\n",
       "                        date             person   \n",
       "0  2019-12-31T00:00:00+00:00   Elizabeth Warren  \\\n",
       "1  2019-12-31T00:00:00+00:00         Tom Steyer   \n",
       "2  2019-12-31T00:00:00+00:00    Joseph R. Biden   \n",
       "3  2019-12-31T00:00:00+00:00  Michael Bloomberg   \n",
       "4  2019-12-31T00:00:00+00:00    Donald J. Trump   \n",
       "\n",
       "                                                link   \n",
       "0  /documents/remarks-old-south-meeting-house-bos...  \\\n",
       "1  /documents/steyer-campaign-press-release-tom-s...   \n",
       "2  /documents/biden-campaign-press-release-biden-...   \n",
       "3  /documents/article-mike-bloomberg-youre-charge...   \n",
       "4  /documents/trump-campaign-statement-happy-new-...   \n",
       "\n",
       "                                          transcript  \n",
       "0  \\n[As prepared for delivery.]\\nIn a few hours,...  \n",
       "1  \\n(SAN FRANCISCO, December 31, 2019) — Today, ...  \n",
       "2  \\nCampaign Continues Growing Super Tuesday Inf...  \n",
       "3  \\nThis article was written by Mike Bloomberg.\\...  \n",
       "4  \\nAs we ring in a New Year, Brad Parscale, Cam...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
